{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23dcbe33-7262-4c46-b23d-510013dcb5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.35.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: requests in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\manta\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\manta\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (58.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.41.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (6.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\manta\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\manta\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\manta\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\manta\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: click in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\manta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\manta\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install tensorflow\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897d4e79-2d3d-4c2c-a3cc-c56aa7044a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\manta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\manta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopw = stopwords.words('english')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3fb1c57-ccb3-4e51-93b8-c90979552369",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2760f6a8-3ebf-4595-ad81-3c64bc25a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"tweets_sentiment.csv\", usecols=['tweet','neg', 'neu', 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd2bc2a-7383-4b9d-b6e5-c61a58735154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bitcoin: The Cyberpunk Cryptocurrency</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitcoin Isn't the Only Cryptocurrency in Town via</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>, a \"cryptocurrency\", went on a tear last week...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm going to make my OWN crypto-currency and e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your momma's cryptocurrency is so virtual, she...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  neg    neu    pos\n",
       "0              Bitcoin: The Cyberpunk Cryptocurrency  0.0  1.000  0.000\n",
       "1  Bitcoin Isn't the Only Cryptocurrency in Town via  0.0  1.000  0.000\n",
       "2  , a \"cryptocurrency\", went on a tear last week...  0.0  1.000  0.000\n",
       "3  I'm going to make my OWN crypto-currency and e...  0.0  0.885  0.115\n",
       "4  Your momma's cryptocurrency is so virtual, she...  0.0  1.000  0.000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad5a05e9-75ae-4367-b603-3fe20ba078ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = []\n",
    "sentiment = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cebb03f-347f-4710-9023-bccc61e23ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c55ce773-0e43-4cab-b47b-572f17a12b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in data.index:\n",
    "    if isinstance(data['tweet'][index], str):\n",
    "        if data['neg'][index] == 0.0 and data['pos'][index] == 0.0:\n",
    "            tweet.append(clean_text(data['tweet'][index]))\n",
    "            sentiment.append(1)\n",
    "        elif data['neg'][index] > data['pos'][index]:\n",
    "            tweet.append(clean_text(data['tweet'][index]))\n",
    "            sentiment.append(0)\n",
    "        elif data['neg'][index] < data['pos'][index]:\n",
    "            tweet.append(clean_text(data['tweet'][index]))\n",
    "            sentiment.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1edc1fa-0a5f-41b9-a7ab-54f88ec3f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"text\": tweet, \"label\": sentiment})\n",
    "data = data.sample(frac = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa670edd-15d1-4d48-8993-a304c56e7fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372750</th>\n",
       "      <td>told twice three times many many future didnt ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665235</th>\n",
       "      <td>easily binance brazil says chad anderson one t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157961</th>\n",
       "      <td>looking nano integrators itd perfect cryptocur...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515591</th>\n",
       "      <td>microbt maker whatsminer bitcoin mining equipm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93798</th>\n",
       "      <td>crypto market hopefully recovers soon traders ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "372750  told twice three times many many future didnt ...      1\n",
       "665235  easily binance brazil says chad anderson one t...      2\n",
       "157961  looking nano integrators itd perfect cryptocur...      2\n",
       "515591  microbt maker whatsminer bitcoin mining equipm...      1\n",
       "93798   crypto market hopefully recovers soon traders ...      2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4cc9043-2e97-46cc-8713-794b8e31ca57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82283, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1efd5fb-b3d9-4c21-bc93-10ba7eb9f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c4b9172-3f84-4e99-864f-b55c24b0d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_dataset = data.sample(frac =.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76548145-41ea-47ba-8f13-af3e2456dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.sample(frac = 0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e66894ca-fd46-4f06-b766-f30e88b07c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.sample(frac = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40409694-8056-414d-9585-96a3aea0d9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(_data):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in tqdm(_data['text']):\n",
    "\n",
    "        #encode text\n",
    "        encoded_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids.append(encoded_text['input_ids'])\n",
    "        attention_masks.append(encoded_text['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    labels = torch.tensor(_data['label'].values)\n",
    "\n",
    "    return input_ids, attention_masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a96ac610-0783-4c94-9da5-ca4dab55b9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/57598 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\manta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 57598/57598 [00:40<00:00, 1410.82it/s]\n"
     ]
    }
   ],
   "source": [
    "train_inputs = tokenize_text(train)\n",
    "\n",
    "train_data = TensorDataset(train_inputs[0], train_inputs[1], train_inputs[2])\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38ceeead-4014-44a6-89b4-8f059ee272af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 16457/16457 [00:10<00:00, 1576.17it/s]\n"
     ]
    }
   ],
   "source": [
    "val_inputs = tokenize_text(test)\n",
    "\n",
    "val_data = TensorDataset(val_inputs[0], val_inputs[1], val_inputs[2])\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6787fadf-0607-4ebe-9262-62dce97693ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\manta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05304ddf-a1a5-4769-83be-91fcd57320e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train['text'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train['label'].tolist()\n",
    ")).shuffle(100).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dda6c48-adfe-4f6b-819b-d6b28a4864f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_encodings = tokenizer(test['text'].tolist(), truncation=True, padding=True)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    test['label'].tolist()\n",
    ")).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76f23c80-f32b-4b16-a2aa-02e8ad119e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b7255a4-6727-45ec-a247-97800ac08a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7d951ac-54d6-468c-bb0f-85ad4a54958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd70831b-5525-422f-a6ca-241a6138c469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\manta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "3600/3600 [==============================] - 9800s 3s/step - loss: 0.4070 - accuracy: 0.8548 - val_loss: 0.2948 - val_accuracy: 0.9100\n",
      "Epoch 2/5\n",
      "3600/3600 [==============================] - 6897s 2s/step - loss: 0.2736 - accuracy: 0.9123 - val_loss: 0.2381 - val_accuracy: 0.9287\n",
      "Epoch 3/5\n",
      "3600/3600 [==============================] - 9682s 3s/step - loss: 0.2018 - accuracy: 0.9375 - val_loss: 0.2015 - val_accuracy: 0.9392\n",
      "Epoch 4/5\n",
      "3600/3600 [==============================] - 9646s 3s/step - loss: 0.1419 - accuracy: 0.9565 - val_loss: 0.2249 - val_accuracy: 0.9315\n",
      "Epoch 5/5\n",
      "3600/3600 [==============================] - 15163s 4s/step - loss: 0.0974 - accuracy: 0.9701 - val_loss: 0.1792 - val_accuracy: 0.9507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15399fd2e80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=val_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e48e3e7-d598-49c4-8bc2-8f81275d5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62a9657b-a09e-4055-8444-c0432f934cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 335s 646ms/step\n"
     ]
    }
   ],
   "source": [
    "new_encodings = tokenizer(final_test_dataset['text'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "new_dataset = tf.data.Dataset.from_tensor_slices(dict(new_encodings)).batch(16)\n",
    "\n",
    "predictions = model.predict(new_dataset)\n",
    "\n",
    "predicted_classes = tf.argmax(predictions.logits, axis=1)\n",
    "\n",
    "for predicted_class in predicted_classes:\n",
    "    preds.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e88bbbf2-baf5-4cbc-9bf3-d8c161726770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90      1408\n",
      "           1       0.96      0.93      0.94      2136\n",
      "           2       0.94      0.97      0.96      4684\n",
      "\n",
      "    accuracy                           0.95      8228\n",
      "   macro avg       0.94      0.92      0.93      8228\n",
      "weighted avg       0.94      0.95      0.94      8228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(final_test_dataset['label'].tolist(), preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "673fbaf3-da74-4b02-ba85-591e0391c710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.50656295576081\n",
      "94.37007739008291\n",
      "93.36754984849553\n",
      "92.46463826573529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "print(accuracy_score(final_test_dataset['label'].tolist(), preds) * 100)\n",
    "print(precision_score(final_test_dataset['label'].tolist(), preds, average='macro') * 100)\n",
    "print(f1_score(final_test_dataset['label'].tolist(), preds, average='macro') * 100)\n",
    "print(recall_score(final_test_dataset['label'].tolist(), preds, average='macro') * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ea5eb6b-5760-4302-9684-37fa66b10067",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('TFDistillBERTFineTuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4638ce7b-3bb1-4d74-9f7f-13f64446911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'zip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!zip -r model.zip TFDistillBERTFineTuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62baf723-f7b8-4c9e-93d3-cad7b1c96d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at TFDistillBERTFineTuned were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at TFDistillBERTFineTuned and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_ = TFDistilBertForSequenceClassification.from_pretrained('TFDistillBERTFineTuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89fd25bf-5c04-44a5-8061-2092f1e625bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "856e3216-7f7f-4a80-aead-67a1135556b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 340s 655ms/step\n"
     ]
    }
   ],
   "source": [
    "new_encodings = tokenizer(final_test_dataset['text'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "new_dataset = tf.data.Dataset.from_tensor_slices(dict(new_encodings)).batch(16)\n",
    "\n",
    "predictions = model_.predict(new_dataset)\n",
    "\n",
    "predicted_classes = tf.argmax(predictions.logits, axis=1)\n",
    "\n",
    "for predicted_class in predicted_classes:\n",
    "    preds.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a92b04fb-a5ff-4f35-9372-22448ac51316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90      1408\n",
      "           1       0.96      0.93      0.94      2136\n",
      "           2       0.94      0.97      0.96      4684\n",
      "\n",
      "    accuracy                           0.95      8228\n",
      "   macro avg       0.94      0.92      0.93      8228\n",
      "weighted avg       0.94      0.95      0.94      8228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(final_test_dataset['label'].tolist(), preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc224fea-717c-429c-aeeb-7140bbcad027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1221,   34,  153],\n",
       "       [  26, 1992,  118],\n",
       "       [  66,   55, 4563]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(final_test_dataset['label'].tolist(), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f53f1c5-f8fa-45e6-86a8-0403c9134123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
